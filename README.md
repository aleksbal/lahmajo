# lahmajo
Basic web wrapper for local LLama model (deployed as Ollama) to augment the prompts using generic prompt templates, RAG, context etc.

Ollama shall be up and running on a local machine in order to the service to work properly.
